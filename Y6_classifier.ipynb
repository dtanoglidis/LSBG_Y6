{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sound-poetry",
   "metadata": {},
   "source": [
    "# A classifier for DES Y6 objects\n",
    "\n",
    "In this notebook I train and test different classifers that can effectively separate LSBGs from artifacts in the DES Y6 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "developmental-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic packages\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "# Scikit-learn\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Matplotlib, urlib etc \n",
    "import urllib\n",
    "import urllib.request\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "# =========================================\n",
    "# =========================================\n",
    "# Adjust rc parameters to make plots pretty\n",
    "def plot_pretty(dpi=200, fontsize=9):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.rc(\"savefig\", dpi=dpi)       # dpi resolution of saved image files\n",
    "    # if you have LaTeX installed on your laptop, uncomment the line below for prettier labels\n",
    "    #plt.rc('text', usetex=True)      # use LaTeX to process labels\n",
    "    plt.rc('font', size=fontsize)    # fontsize\n",
    "    plt.rc('xtick', direction='in')  # make axes ticks point inward\n",
    "    plt.rc('ytick', direction='in')\n",
    "    plt.rc('xtick.major', pad=10) \n",
    "    plt.rc('xtick.minor', pad=5)\n",
    "    plt.rc('ytick.major', pad=10) \n",
    "    plt.rc('ytick.minor', pad=5)\n",
    "    plt.rc('lines', dotted_pattern = [0.5, 1.1]) # fix dotted lines\n",
    "\n",
    "    return\n",
    "plot_pretty()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ongoing-projection",
   "metadata": {},
   "source": [
    "**Helper functions**\n",
    "\n",
    "Write a function that creates and plots 100 cutouts of objects , given their coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cellular-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_plot(ra_arr,dec_arr,numb,save=True):\n",
    "    \"\"\"\n",
    "    This function gets the coordinates (ra,dec) of \n",
    "    a number of objects and outputs a figure with 100 cutouts\n",
    "    \n",
    "    Inputs:\n",
    "    ra_arr - 1D array of RAs\n",
    "    dec_arr - 1D array of DECs\n",
    "    numb - where to start from creating the cutouts\n",
    "    if 0, gives you the first 100 objects; if 100 gives you the next 100 etc\n",
    "    save - whether to save the image or not, defualt = True\n",
    "    \"\"\"\n",
    "    # Initialize array\n",
    "    Array = np.zeros([100,64,64,3])\n",
    "    \n",
    "    zoom=15\n",
    "    \n",
    "    # Populate array\n",
    "    for i in range(100):\n",
    "        j = i + numb\n",
    "        # Give a name to the figure. Name them as \"Image_cand_(i).jpb\n",
    "        # Where i is the number of the candidate\n",
    "        # This is easy to change to ra, dec or coadd ID or whatever...\n",
    "        fig_name = \"Image_cand.jpg\"\n",
    "    \n",
    "        #Create now the name of the URL\n",
    "        # This need to have as inputs (that change) the RA, DEC of each objec and zoom\n",
    "        RA_loc = ra_arr[j] #The RA of the i-th object\n",
    "        DEC_loc = dec_arr[j] # The DEC of the i-th object\n",
    "    \n",
    "        url_name = \"http://legacysurvey.org//viewer/jpeg-cutout?ra={0}&dec={1}&zoom={2}&layer=des-dr1\".format(RA_loc,DEC_loc,zoom)\n",
    "        #url_name = \"https://www.legacysurvey.org//viewer/jpeg-cutout?ra={0}&dec={1}&layer=hsc2&zoom={2}\".format(RA_loc,DEC_loc,zoom)\n",
    "        urllib.request.urlretrieve(url_name, fig_name) #Retrieves and saves each image\n",
    "    \n",
    "        image = Image.open('Image_cand.jpg')\n",
    "        # resize image\n",
    "        new_image = image.resize((64, 64))\n",
    "        # Convert the image to an RGB array\n",
    "        im_array = np.asarray(new_image)\n",
    "    \n",
    "        Array[i] = im_array\n",
    "    \n",
    "        clear_output(wait=True)\n",
    "        print('runs:',i)\n",
    "    \n",
    "    # ==========================================\n",
    "    # Plot the cutouts generated in an array\n",
    "    n_rows = 20\n",
    "    n_cols = 5\n",
    "    \n",
    "    plt.figure(figsize=(4*n_cols*0.7, 4*n_rows*0.7))\n",
    "\n",
    "    for i in range(n_rows*n_cols):\n",
    "        #if (i==3):\n",
    "        #    plt.title(\"Matched objects\",fontsize=25)\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        plt.imshow(Array[i]/255.)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    if (save==True):\n",
    "        plt.savefig(\"Examples.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-cherry",
   "metadata": {},
   "source": [
    "### Y6 Catalog around Fornax (or other area)\n",
    "\n",
    "Here, we first import the full DES Y6 skim catalog, then we write a function that selects a region around a given coordinate (e.g. 1 degree around the center of Fornax) and create a feature matrix that can be subsequently used to perform classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "proper-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "DES_Y6 = fits.open('y6_gold_2_0_lsb_skim.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "respective-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import full catalog with all the properties\n",
    "data = DES_Y6[1].data[:]\n",
    "\n",
    "# Import RA and DEC coordinates\n",
    "ra = data['RA']\n",
    "dec = data['DEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "previous-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_mat_around(ra_c,dec_c,degs=1.):\n",
    "    \"\"\"\n",
    "    Function that returns arrays of coordinates \n",
    "    and a feature matrix to be used for classification,\n",
    "    around given coordinates.\n",
    "    -------------------------\n",
    "    Input:\n",
    "    ra_c - central coordinate/RA\n",
    "    dec_c - central coordinate/DEC\n",
    "    degs - how many degrees around the center to keep/default=1\n",
    "    -------------------------\n",
    "    Output:\n",
    "    ras_in - coordinates of objects that pass the criteria/RA\n",
    "    decs_in - coordinates of objects that pass the criteria/DECs\n",
    "    X_feat - feature matrix (unnormalized) of the objects that pass the criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define box of coordinates\n",
    "    box = (ra>(ra_c-degs))&(ra<(ra_c+degs))&(dec>(dec_c-degs))&(dec<-(dec_c+degs))\n",
    "    \n",
    "    # Keep only coordinates & features within the above coordinate box\n",
    "    ras_in = ra[box]\n",
    "    decs_in = dec[box]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-binding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "square-demographic",
   "metadata": {},
   "source": [
    "## Part I: Train on Y3, check on Y6\n",
    "\n",
    "In this part we train the classifier on objects from the Y3 catalog, with the Y3 parameters (without cross-matching the two catalogs)\n",
    "\n",
    "We check two different types of artifacts; randomly selected and those visually rejected (harder to classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "light-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalogs as dataframes\n",
    "LSBG_Y3_df = pd.read_csv('random_LSBGs_all.csv') # LSBGs\n",
    "Artifacts_1_df = pd.read_csv('random_negative_all_1.csv') #\"Easy artifacts\n",
    "Artifacts_2_df = pd.read_csv('random_negative_all_2.csv') #\"Hard\" artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "funded-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 24)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(LSBG_Y3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-midwest",
   "metadata": {},
   "source": [
    "Get matrices with numberical values of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "grateful-image",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20)\n"
     ]
    }
   ],
   "source": [
    "Mat_LSBG = LSBG_Y3_df.iloc[:,4:].values\n",
    "Mat_Art_1 = Artifacts_1_df.iloc[:,4:].values\n",
    "Mat_Art_2 = Artifacts_2_df.iloc[:,4:].values\n",
    "print(np.shape(Mat_LSBG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-titanium",
   "metadata": {},
   "source": [
    "Get the **coordinates** of the objects - we will need that for visual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exotic-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSBGs\n",
    "ra_LSBG = LSBG_Y3_df['ra'].values\n",
    "dec_LSBG = LSBG_Y3_df['dec'].values\n",
    "\n",
    "# Artifacts 1\n",
    "ra_Art_1 = Artifacts_1_df['ra'].values\n",
    "dec_Art_1 = Artifacts_1_df['dec'].values\n",
    "\n",
    "# Artifacts 2 \n",
    "ra_Art_2 = Artifacts_2_df['ra'].values\n",
    "dec_Art_2 = Artifacts_2_df['dec'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-beatles",
   "metadata": {},
   "source": [
    "**Feature Engineering**\n",
    "\n",
    "Perform Feature engineering.\n",
    "\n",
    "Define ellipticity and colors (at first)\n",
    "Then we can add extra features, or check if some of them are reduntant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "after-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== For LSBGs ============================\n",
    "# Ellipticity\n",
    "Ell_LSBG = 1 - LSBG_Y3_df['B_IMAGE'].values/LSBG_Y3_df['A_IMAGE'].values\n",
    "\n",
    "# Colors \n",
    "col_g_r_LSBG = LSBG_Y3_df['mag_auto_g'].values - LSBG_Y3_df['mag_auto_r'].values\n",
    "col_g_i_LSBG = LSBG_Y3_df['mag_auto_g'].values - LSBG_Y3_df['mag_auto_i'].values\n",
    "col_r_i_LSBG = LSBG_Y3_df['mag_auto_r'].values - LSBG_Y3_df['mag_auto_i'].values\n",
    "\n",
    "# ==================== For Artifacts of type 1 ==============\n",
    "# Ellipticity\n",
    "Ell_Art_1 = 1 - Artifacts_1_df['B_IMAGE'].values/Artifacts_1_df['A_IMAGE'].values\n",
    "\n",
    "# Colors\n",
    "col_g_r_Art_1 = Artifacts_1_df['mag_auto_g'].values - Artifacts_1_df['mag_auto_r'].values\n",
    "col_g_i_Art_1 = Artifacts_1_df['mag_auto_g'].values - Artifacts_1_df['mag_auto_i'].values\n",
    "col_r_i_Art_1 = Artifacts_1_df['mag_auto_r'].values - Artifacts_1_df['mag_auto_i'].values\n",
    "\n",
    "# ==================== For Artifacts of type 2 ==============\n",
    "# Ellipticity\n",
    "Ell_Art_2 = 1 - Artifacts_2_df['B_IMAGE'].values/Artifacts_2_df['A_IMAGE'].values\n",
    "\n",
    "# Colors\n",
    "col_g_r_Art_2 = Artifacts_2_df['mag_auto_g'].values - Artifacts_2_df['mag_auto_r'].values\n",
    "col_g_i_Art_2 = Artifacts_2_df['mag_auto_g'].values - Artifacts_2_df['mag_auto_i'].values\n",
    "col_r_i_Art_2 = Artifacts_2_df['mag_auto_r'].values - Artifacts_2_df['mag_auto_i'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-compensation",
   "metadata": {},
   "source": [
    "Integrate the new engineered features to the feature matrices of LSBGs and artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "patient-closer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 24)\n"
     ]
    }
   ],
   "source": [
    "# LSBGs \n",
    "X_LSBG = np.column_stack((Ell_LSBG,col_g_r_LSBG,col_g_i_LSBG,col_r_i_LSBG,Mat_LSBG))\n",
    "# Artifacts 1\n",
    "X_Art_1 = np.column_stack((Ell_Art_1,col_g_r_Art_1,col_g_i_Art_1,col_r_i_Art_1,Mat_Art_1))\n",
    "# Artifacts 2\n",
    "X_Art_2 = np.column_stack((Ell_Art_2,col_g_r_Art_2,col_g_i_Art_2,col_r_i_Art_2,Mat_Art_2))\n",
    "\n",
    "# ============================\n",
    "# Let's print shape to check that everything is ok!\n",
    "print(np.shape(X_LSBG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-intent",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-repository",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-garage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-consumer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
